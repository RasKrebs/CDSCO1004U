{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Notebook To Extract Data`\n",
    "\n",
    "This notebook is used for extracting, processing and loading images needed for training *YOLOv5*, *TinyVGG* and the *Simplified Xception*.\n",
    "\n",
    "**Note**\\\n",
    "YOLOv5 requires that data is saved within its directory. Therefore, after having run the section for YOLO, locate the images within **`dependencies/yolov_data`**, and move these into **`dependencies/yolov5/datasets`** (This is only necessary if you are cloning from Github)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library import\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import Bunch\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import uuid\n",
    "from PIL import Image\n",
    " \n",
    "from utils.GenerateFileList import unpack_json, balanced_category_sampling\n",
    "from utils.FetchImages import download_images\n",
    "from utils.ImageJsonGenerator import create_subset_json\n",
    "from utils.YOLOLabelGenerator import generate_txt_files\n",
    "from utils.ImageModifier import resize_images\n",
    "from utils.DataLoader import import_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Paths\n",
    "WORKING_DIRECTORY = os.getcwd()\n",
    "DEPENDENCIES = os.path.join(WORKING_DIRECTORY, 'dependencies')\n",
    "DATA_PATH = os.path.join(DEPENDENCIES, 'yolo_data')\n",
    "COCO_ANNOTATIONS = os.path.join(DATA_PATH, 'coco2017')\n",
    "\n",
    "TRAINING_PATH = os.path.join(DATA_PATH, 'training')\n",
    "TRAINING_IMAGES = os.path.join(TRAINING_PATH, 'images')\n",
    "TRAINING_DATA = os.path.join(TRAINING_PATH, 'data')\n",
    "TRAINING_LABEL = os.path.join(TRAINING_PATH, 'labels')\n",
    "\n",
    "TEST_PATH = os.path.join(DATA_PATH, 'test')\n",
    "TEST_IMAGES = os.path.join(TEST_PATH, 'images')\n",
    "TEST_DATA = os.path.join(TEST_PATH, 'data')\n",
    "TEST_LABEL = os.path.join(TEST_PATH, 'labels')\n",
    "\n",
    "VALIDATION_PATH = os.path.join(DATA_PATH, 'validation')\n",
    "VALIDATION_IMAGES = os.path.join(VALIDATION_PATH, 'images')\n",
    "VALIDATION_DATA = os.path.join(VALIDATION_PATH, 'data')\n",
    "VALIDATION_LABELS = os.path.join(VALIDATION_PATH, 'labels')\n",
    "\n",
    "# Combining all paths\n",
    "PATHS = Bunch(\n",
    "    WORKING_DIRECTORY=WORKING_DIRECTORY,\n",
    "    DEPENDENCIES=DEPENDENCIES,\n",
    "    DATA_PATH=DATA_PATH,\n",
    "    COCO_ANNOTATIONS=COCO_ANNOTATIONS,\n",
    "    TRAINING_PATH=TRAINING_PATH,\n",
    "    TRAINING_IMAGES=TRAINING_IMAGES,\n",
    "    TRAINING_DATA=TRAINING_DATA,\n",
    "    TRAINING_LABEL=TRAINING_LABEL,\n",
    "    TEST_PATH=TEST_PATH,\n",
    "    TEST_IMAGES=TEST_IMAGES,\n",
    "    TEST_DATA=TEST_DATA,\n",
    "    TEST_LABEL=TEST_LABEL,\n",
    "    VALIDATION_PATH=VALIDATION_PATH,\n",
    "    VALIDATION_IMAGES=VALIDATION_IMAGES,\n",
    "    VALIDATION_DATA=VALIDATION_DATA,\n",
    "    VALIDATION_LABELS=VALIDATION_LABELS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"traffic light\", \"bus\", \"train\", \"truck\", \"car\", \"bicycle\", \"person\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `YOLOv5 DATA EXTRACTION`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. + 2. Generate directories and download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating relevant directories\n",
    "for p in PATHS.values():\n",
    "    if not os.path.exists(p):\n",
    "        print(f'{os.path.basename(p)} does not exists')\n",
    "        os.makedirs(p)\n",
    "\n",
    "# Downloading COCO annotations if none exists\n",
    "# Download coco annotations from\n",
    "if not os.path.exists(os.path.join(PATHS.COCO_ANNOTATIONS, 'instances_train2017.json')):\n",
    "    print('Downloading training annotations...')\n",
    "    URL = \"https://huggingface.co/datasets/merve/coco/resolve/main/annotations/instances_train2017.json\"\n",
    "    train_annotation_url = requests.get(URL).content\n",
    "\n",
    "    with open(os.path.join(PATHS.COCO_ANNOTATIONS, 'instances_train2017.json'), \"wb\") as file:\n",
    "        file.write(train_annotation_url)\n",
    "    print('Done')\n",
    "else:\n",
    "    print('Training annotations already exists')\n",
    "\n",
    "if not os.path.exists(os.path.join(PATHS.COCO_ANNOTATIONS, 'instances_val2017.json')):\n",
    "    print('Downloading validation annotations...')\n",
    "    URL = \"https://huggingface.co/datasets/merve/coco/resolve/main/annotations/instances_val2017.json\"\n",
    "    train_annotation_url = requests.get(URL).content\n",
    "\n",
    "    with open(os.path.join(PATHS.COCO_ANNOTATIONS, 'instances_val2017.json'), \"wb\") as file:\n",
    "        file.write(train_annotation_url)\n",
    "    print('Done')\n",
    "else:\n",
    "    print('Validation annotations already exists')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3. Extract necessary information from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpacking instances json\n",
    "train_files, train_data = unpack_json(labels=CATEGORIES, annotation_file_name='instances_train2017.json',\n",
    "                                      max_img_categories=3, annotation_path=PATHS.COCO_ANNOTATIONS)\n",
    "\n",
    "val_files, val_data = unpack_json(labels=CATEGORIES, annotation_file_name='instances_val2017.json',\n",
    "                                  max_img_categories=3, annotation_path=PATHS.COCO_ANNOTATIONS)\n",
    "\n",
    "test_files, test_data = unpack_json(labels=CATEGORIES, annotation_file_name='instances_val2017.json',\n",
    "                                  max_img_categories=3, annotation_path=PATHS.COCO_ANNOTATIONS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Balance samples equally across categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing categories, so all equally represented\n",
    "train_images, train_annot = balanced_category_sampling(files=train_files,\n",
    "                                                       data=train_data,\n",
    "                                                       size=2500,\n",
    "                                                       categories=CATEGORIES)\n",
    "\n",
    "\n",
    "test_images, test_annot = balanced_category_sampling(files=val_files,\n",
    "                                                     data=val_data,\n",
    "                                                     size=500,\n",
    "                                                     categories=CATEGORIES,\n",
    "                                                     list_of_files_to_exclude=list(train_files.keys()))\n",
    "\n",
    "\n",
    "val_images, val_annot = balanced_category_sampling(files=val_files,\n",
    "                                                   data=val_data,\n",
    "                                                   size=500,\n",
    "                                                   categories=CATEGORIES,\n",
    "                                                   list_of_files_to_exclude=list(train_files.keys()))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Download Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking first to see how many existing files there are\n",
    "def extract_existing_files(size, path, images):\n",
    "    # Fetch files in path\n",
    "    files = os.listdir(path)\n",
    "    \n",
    "    if size <= len(files):\n",
    "        print('Already sufficient images in folder')\n",
    "        return None\n",
    "    \n",
    "    elif len(files) < size:\n",
    "        print(f'Existing files in folder, removing {len(files)} from {len(images)}')\n",
    "        images = images[-images.file_name.isin(files)]\n",
    "        images = images.head(size)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = extract_existing_files(2500, PATHS.TRAINING_IMAGES, train_images)\n",
    "test_images = extract_existing_files(500, PATHS.TEST_IMAGES, test_images)\n",
    "val_images = extract_existing_files(500, PATHS.VALIDATION_IMAGES, val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images\n",
    "try:\n",
    "    download_images(train_images, PATHS.TRAINING_IMAGES)\n",
    "except TypeError:\n",
    "    print('Image count is already sufficient for traininig')\n",
    "    \n",
    "try:\n",
    "    download_images(val_images, PATHS.VALIDATION_IMAGES)\n",
    "except TypeError:\n",
    "    print('Image count is already sufficient for validation')\n",
    "\n",
    "try:\n",
    "    download_images(test_images, PATHS.TEST_IMAGES)\n",
    "except TypeError:\n",
    "    print('Image count is already sufficient for test')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Resize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing images to 640x640\n",
    "resize_images(PATHS.TRAINING_IMAGES)\n",
    "resize_images(PATHS.TEST_IMAGES)\n",
    "resize_images(PATHS.VALIDATION_IMAGES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.  Generate subset instance json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating new instance jsons for each subset\n",
    "create_subset_json(data = train_data,\n",
    "                          file_name='train',\n",
    "                          image_path = PATHS.TRAINING_IMAGES,\n",
    "                          data_path= PATHS.TRAINING_DATA) # Training JSON\n",
    "\n",
    "create_subset_json(data=val_data,\n",
    "                   file_name='validation',\n",
    "                   image_path=PATHS.VALIDATION_IMAGES,\n",
    "                   data_path=PATHS.VALIDATION_DATA)  # Val JSON\n",
    "\n",
    "create_subset_json(data=test_data,\n",
    "                   file_name='test',\n",
    "                   image_path=PATHS.TEST_IMAGES,\n",
    "                   data_path=PATHS.TEST_DATA)  # Test JSON"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Generate yolo text labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate yolo .txt files\n",
    "generate_txt_files(data_path=PATHS.TRAINING_DATA,\n",
    "                  img_path=PATHS.TRAINING_IMAGES,\n",
    "                  label_path=PATHS.TRAINING_LABEL,\n",
    "                  categories=CATEGORIES,\n",
    "                  data_filename = 'train.json')\n",
    "\n",
    "ok = generate_txt_files(data_path=PATHS.TEST_DATA, \n",
    "                        img_path=PATHS.TEST_IMAGES,\n",
    "                        label_path=PATHS.TEST_LABEL,\n",
    "                        categories=CATEGORIES,\n",
    "                        data_filename='test.json')\n",
    "\n",
    "generate_txt_files(data_path=PATHS.VALIDATION_DATA,\n",
    "                   img_path=PATHS.VALIDATION_IMAGES,\n",
    "                   label_path=PATHS.VALIDATION_LABELS,\n",
    "                   categories=CATEGORIES,\n",
    "                   data_filename='validation.json') # Validation labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TinyVGG and Simplified Xception Model Data Extrcation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed pahts\n",
    "WORKING_DIRECTORY = os.getcwd()\n",
    "DATA_FOLDER = os.path.join(WORKING_DIRECTORY, 'dependencies', 'yolo_data', 'coco2017')\n",
    "TRAINING_FOLDER = os.path.join(WORKING_DIRECTORY, 'dependencies', 'cnn_data', 'training')\n",
    "TEST_FOLDER = os.path.join(WORKING_DIRECTORY, 'dependencies', 'cnn_data', 'test')\n",
    "\n",
    "# Specifying desired categories\n",
    "CATEGORIES = [\"car\", \"bicycle\", \"person\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data using import data function\n",
    "data = import_data(DATA_FOLDER, file_name='instances_train2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate annotations dataframe\n",
    "def generate_annot_df(bunch, cats):\n",
    "\n",
    "    # Filename and URL\n",
    "    dic = {x['id']: x['file_name'] for x in bunch.images}\n",
    "    url = {x['id']: x['coco_url'] for x in bunch.images}\n",
    "\n",
    "    # Extract id for categories\n",
    "    category_ids = {cat['id']: cat['name']\n",
    "                    for cat in bunch.catagories if cat['name'] in cats}\n",
    "\n",
    "    df = pd.DataFrame(bunch.annotations)\n",
    "\n",
    "    # Removing images of crowds\n",
    "    df = df[-df.image_id.isin(df[df.iscrowd == 1].image_id.to_list())\n",
    "            ][['image_id', 'area', 'bbox', 'category_id']]\n",
    "\n",
    "    # Adding file name to datafram\n",
    "    df['file_name'] = df['image_id'].map(dic)\n",
    "\n",
    "    # Adding coco url needed for extraction\n",
    "    df['coco_url'] = df['image_id'].map(url)\n",
    "\n",
    "    # Unpacking bounding box column\n",
    "    df = df.assign(\n",
    "        x_min=lambda x: x['bbox'].apply(lambda x: x[0]),\n",
    "        y_min=lambda x: x['bbox'].apply(lambda x: x[1]),\n",
    "        w=lambda x: x['bbox'].apply(lambda x: x[2]),\n",
    "        h=lambda x: x['bbox'].apply(lambda x: x[3]),\n",
    "        x_max=lambda x: x.x_min + x.w,\n",
    "        y_max=lambda x: x.y_min + x.h)\n",
    "\n",
    "    # Resetting index and dropping all annotations outside of desired list of categories\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df[df.category_id.isin(category_ids.keys())][['file_name', 'coco_url',\n",
    "                                                       'image_id', 'category_id', 'area', 'bbox', 'x_min', 'y_min', 'x_max', 'y_max']]\n",
    "\n",
    "    # Creating new category ids (so that they are not 2, 5 , 7, and instead, 0, 1, 2)\n",
    "    categories = {old: new for (new, old) in zip(\n",
    "        range(len(category_ids.keys())), category_ids.keys())}\n",
    "\n",
    "    # Get category names and add to dataframe\n",
    "    category_names = {value: category_ids[key]\n",
    "                      for key, value in categories.items()}\n",
    "    df.category_id = df.category_id.map(categories)\n",
    "    df['category_name'] = df.category_id.map(category_names)\n",
    "\n",
    "    return df, category_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot, category_names = generate_annot_df(data, CATEGORIES)\n",
    "# del data # Removing data dict to not take up too much ram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_crop_and_save_image(annot_df, train_folder, test_folder, images_per_category=1000, test_size=0.15):\n",
    "    \n",
    "    # Categories\n",
    "    cats = ['person', 'car', 'bicycle']\n",
    "    \n",
    "    # Extract equal number of images based on biggest bbox from annotations within desired categories\n",
    "    train = annot_df[annot_df.category_name.isin(cats)].sort_values(by='area', ascending=False).groupby(\n",
    "        'category_id').apply(lambda x: x[:images_per_category]).reset_index(drop=True)\n",
    "    \n",
    "    # Same for test set\n",
    "    test = annot_df[(annot_df.category_name.isin(cats)) & (annot_df.image_id.isin(train.image_id.to_list()))].sort_values(by='area', ascending=False).groupby(\n",
    "        'category_id').apply(lambda x: x[:round(images_per_category*test_size)]).reset_index(drop=True)\n",
    "    \n",
    "        \n",
    "    for data, folder in zip([train, test],[train_folder, test_folder]):\n",
    "        # Creating directories to store images (TensorFlow can infer labels from directory structure)\n",
    "        for cat in cats:\n",
    "            if not os.path.exists(os.path.join(folder, cat)):\n",
    "                os.makedirs(os.path.join(folder, cat))\n",
    "    \n",
    "        \n",
    "        print(f'Cropping and moving: {len(data)} images')\n",
    "        images_done = 0\n",
    "    \n",
    "        # New image size\n",
    "        new_size = (250, 250)\n",
    "    \n",
    "        # looping through dataset to crop images according to category\n",
    "        for ind, row in data.iterrows():\n",
    "            images_done += 1\n",
    "    \n",
    "            # Fetching image contents\n",
    "            response = requests.get(row.coco_url)\n",
    "    \n",
    "            # Cropping images based on bbox\n",
    "            (left, top, right, bottom) = row.x_min, row.y_min, row.x_max, row.y_max\n",
    "    \n",
    "            # Create uuid for naming (only using the first part of the uuid), to use for renaming\n",
    "            uid = str(uuid.uuid4()).split('-')[0]\n",
    "    \n",
    "            # Extract, transform and load images into new folder\n",
    "            with Image.open(BytesIO(response.content)) as img:\n",
    "                img = img.crop((left, top, right, bottom))\n",
    "                img = img.resize(new_size)\n",
    "                img.save(\n",
    "                    f'{os.path.join(folder, row.category_name)}/{row.category_name}_{uid}.jpg')\n",
    "    \n",
    "            print(f'Images done: {images_done}/{len(data)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_crop_and_save_image(annot, TRAINING_FOLDER, TEST_FOLDER) # TensorFlow automatically seperates train set into train and validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
