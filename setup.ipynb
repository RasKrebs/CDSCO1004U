{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Notebook version of setup.py. Enables modification to the setup procedure`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library import\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import Bunch\n",
    "import requests\n",
    " \n",
    "from utils.GenerateFileList import unpack_json, balanced_category_sampling\n",
    "from utils.FetchImages import download_images\n",
    "from utils.ImageJsonGenerator import create_subset_json\n",
    "from utils.YOLOLabelGenerator import generate_txt_files\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Paths\n",
    "WORKING_DIRECTORY = os.getcwd()\n",
    "DEPENDENCIES = os.path.join(WORKING_DIRECTORY, 'dependencies')\n",
    "DATA_PATH = os.path.join(DEPENDENCIES, 'yolo_data')\n",
    "COCO_ANNOTATIONS = os.path.join(DATA_PATH, 'coco2017')\n",
    "\n",
    "TRAINING_PATH = os.path.join(DATA_PATH, 'training')\n",
    "TRAINING_IMAGES = os.path.join(TRAINING_PATH, 'images')\n",
    "TRAINING_DATA = os.path.join(TRAINING_PATH, 'data')\n",
    "TRAINING_LABEL = os.path.join(TRAINING_PATH, 'labels')\n",
    "\n",
    "TEST_PATH = os.path.join(DATA_PATH, 'test')\n",
    "TEST_IMAGES = os.path.join(TEST_PATH, 'images')\n",
    "TEST_DATA = os.path.join(TEST_PATH, 'data')\n",
    "TEST_LABEL = os.path.join(TEST_PATH, 'labels')\n",
    "\n",
    "VALIDATION_PATH = os.path.join(DATA_PATH, 'validation')\n",
    "VALIDATION_IMAGES = os.path.join(VALIDATION_PATH, 'images')\n",
    "VALIDATION_DATA = os.path.join(VALIDATION_PATH, 'data')\n",
    "VALIDATION_LABELS = os.path.join(VALIDATION_PATH, 'labels')\n",
    "\n",
    "# Combining all paths\n",
    "PATHS = Bunch(\n",
    "    WORKING_DIRECTORY=WORKING_DIRECTORY,\n",
    "    DEPENDENCIES=DEPENDENCIES,\n",
    "    DATA_PATH=DATA_PATH,\n",
    "    COCO_ANNOTATIONS=COCO_ANNOTATIONS,\n",
    "    TRAINING_PATH=TRAINING_PATH,\n",
    "    TRAINING_IMAGES=TRAINING_IMAGES,\n",
    "    TRAINING_DATA=TRAINING_DATA,\n",
    "    TRAINING_LABEL=TRAINING_LABEL,\n",
    "    TEST_PATH=TEST_PATH,\n",
    "    TEST_IMAGES=TEST_IMAGES,\n",
    "    TEST_DATA=TEST_DATA,\n",
    "    TEST_LABEL=TEST_LABEL,\n",
    "    VALIDATION_PATH=VALIDATION_PATH,\n",
    "    VALIDATION_IMAGES=VALIDATION_IMAGES,\n",
    "    VALIDATION_DATA=VALIDATION_DATA,\n",
    "    VALIDATION_LABELS=VALIDATION_LABELS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"traffic light\", \"bus\", \"train\", \"truck\", \"car\", \"bicycle\", \"person\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Body"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. + 2. Generate directories and download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating relevant directories\n",
    "for p in PATHS.values():\n",
    "    if not os.path.exists(p):\n",
    "        print(f'{os.path.basename(p)} does not exists')\n",
    "        os.makedirs(p)\n",
    "print('Done')\n",
    "\n",
    "# Downloading COCO annotations if none exists\n",
    "print('(2/x): Downloading COCO annotations...')\n",
    "# Download coco annotations from\n",
    "if not os.path.exists(os.path.join(PATHS.COCO_ANNOTATIONS, 'instances_train2017.json')):\n",
    "    print('Downloading training annotations...')\n",
    "    URL = \"https://huggingface.co/datasets/merve/coco/resolve/main/annotations/instances_train2017.json\"\n",
    "    train_annotation_url = requests.get(URL).content\n",
    "\n",
    "    with open(os.path.join(PATHS.COCO_ANNOTATIONS, 'instances_train2017.json'), \"wb\") as file:\n",
    "        file.write(train_annotation_url)\n",
    "    print('Done')\n",
    "else:\n",
    "    print('Training annotations already exists')\n",
    "\n",
    "if not os.path.exists(os.path.join(PATHS.COCO_ANNOTATIONS, 'instances_val2017.json')):\n",
    "    print('Downloading validation annotations...')\n",
    "    URL = \"https://huggingface.co/datasets/merve/coco/resolve/main/annotations/instances_val2017.json\"\n",
    "    train_annotation_url = requests.get(URL).content\n",
    "\n",
    "    with open(os.path.join(PATHS.COCO_ANNOTATIONS, 'instances_val2017.json'), \"wb\") as file:\n",
    "        file.write(train_annotation_url)\n",
    "    print('Done')\n",
    "else:\n",
    "    print('Validation annotations already exists')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract necessary information from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpacking instances json\n",
    "train_files, train_data = unpack_json(labels=CATEGORIES, annotation_file_name='instances_train2017.json',\n",
    "                                      max_img_categories=3, annotation_path=PATHS.COCO_ANNOTATIONS)\n",
    "\n",
    "val_files, val_data = unpack_json(labels=CATEGORIES, annotation_file_name='instances_val2017.json',\n",
    "                                  max_img_categories=3, annotation_path=PATHS.COCO_ANNOTATIONS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Balance samples equally across categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing categories, so all equally represented\n",
    "train_images, train_annot = balanced_category_sampling(files=train_files,\n",
    "                                          data=train_data,\n",
    "                                          size=2500,\n",
    "                                          categories=CATEGORIES,\n",
    "                                          list_of_files_to_exclude=os.listdir(TRAINING_IMAGES))\n",
    "\n",
    "val_images, val_annot = balanced_category_sampling(files=val_files,\n",
    "                                        data=val_data,\n",
    "                                        size=800,\n",
    "                                        categories=CATEGORIES,\n",
    "                                        list_of_files_to_exclude=list(train_files.keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Download Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 5 % 5 == 0:\n",
    "    print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images\n",
    "print('(5/8): Downloading images...')\n",
    "download_images(train_images, PATHS.TRAINING_IMAGES)\n",
    "download_images(val_images, PATHS.VALIDATION_IMAGES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test set (optional)\n",
    "*This requires that images are already ingested into training images folder. To do this, increase the size training and validation, specifyling which images not to include (e.g. those in training images path - ensures no duplicates). Reason for increasing size is that their is not an abundance of instances in the dataset across all categories*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the two dataframes\n",
    "annot = pd.concat([train_annot, val_annot])\n",
    "img = pd.concat([train_images, val_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sectioning the dataset into two equally large sets, where categories are equally dispersed between them\n",
    "first_half = annot.groupby('category_id').apply(lambda x: x[:round(len(x.category_id)/2)]).reset_index(drop=True).image_id.to_list()\n",
    "sec_half = annot[-annot.image_id.isin(first_half)].image_id.to_list()\n",
    "\n",
    "# Define images to move from validation to test\n",
    "images_to_move = val_images[val_images.id.isin(sec_half)].file_name.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving images\n",
    "for img in images_to_move:\n",
    "    os.rename(os.path.join(VALIDATION_IMAGES, img),\n",
    "              os.path.join(TEST_IMAGES, img)\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'info': train_data['info'],\n",
    "        'licenses': train_data['licenses'],\n",
    "        'images': train_data['images'] + val_data['images'],\n",
    "        'annotations': train_data['annotations'] + val_data['annotations'],\n",
    "        'categories': train_data['categories']}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate subset instance json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating new instance jsons for each subset\n",
    "create_subset_json(data = train_data,\n",
    "                          file_name='train',\n",
    "                          image_path = PATHS.TRAINING_IMAGES,\n",
    "                          data_path= PATHS.TRAINING_DATA) # Training JSON\n",
    "\n",
    "create_subset_json(data=data,\n",
    "                   file_name='validation',\n",
    "                   image_path=PATHS.VALIDATION_IMAGES,\n",
    "                   data_path=PATHS.VALIDATION_DATA)  # Val JSON\n",
    "\n",
    "create_subset_json(data=data,\n",
    "                   file_name='test',\n",
    "                   image_path=PATHS.TEST_IMAGES,\n",
    "                   data_path=PATHS.TEST_DATA)  # Test JSON"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate yolo text labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate yolo .txt files\n",
    "generate_txt_files(data_path=PATHS.TRAINING_DATA,\n",
    "                  img_path=PATHS.TRAINING_IMAGES,\n",
    "                  label_path=PATHS.TRAINING_LABEL,\n",
    "                  categories=CATEGORIES,\n",
    "                  data_filename = 'train.json') # Training labels\n",
    "\n",
    "generate_txt_files(data_path=PATHS.TEST_DATA,\n",
    "                   img_path=PATHS.TEST_IMAGES,\n",
    "                   label_path=PATHS.TEST_LABEL,\n",
    "                   categories=CATEGORIES,\n",
    "                   data_filename='test.json') # Test labels \n",
    "\n",
    "\n",
    "generate_txt_files(data_path=PATHS.VALIDATION_DATA,\n",
    "                   img_path=PATHS.VALIDATION_IMAGES,\n",
    "                   label_path=PATHS.VALIDATION_LABELS,\n",
    "                   categories=CATEGORIES,\n",
    "                   data_filename='validation.json') # Validation labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
