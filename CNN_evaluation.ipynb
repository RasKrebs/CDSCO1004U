{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN and related metrics\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# General\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Image and visualiztaion\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying relevant paths\n",
    "WORKING_DIRECTORY = os.getcwd()\n",
    "DEPENDENCIES = os.path.join(WORKING_DIRECTORY, 'dependencies')\n",
    "MODELS = os.path.join(DEPENDENCIES, 'models')\n",
    "TEST = os.path.join(DEPENDENCIES, 'cnn_data', 'test')\n",
    "YOLO = os.path.join(DEPENDENCIES, 'yolov5')\n",
    "YOLO_MODEL = os.path.join(YOLO, 'exam', 'models')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception = keras.models.load_model(f'{MODELS}/Xception_model_v2.keras')\n",
    "TinyVGG = keras.models.load_model(f'{MODELS}/TinyVGG_Model_v2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TinyVGG.get_compile_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 250, 250\n",
    "\n",
    "# Importing as tensorflow dataset for easy evaluation\n",
    "tensorflow_test = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST,\n",
    "    labels='inferred',\n",
    "    color_mode='rgb',\n",
    "    seed=42,\n",
    "    batch_size=32,\n",
    "    image_size=(img_height, img_width),)\n",
    "\n",
    "# class names\n",
    "class_names = tensorflow_test.class_names\n",
    "class_index = {index: name for index, name in enumerate(class_names)}\n",
    "print(f'Class index of class names {class_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To make image visualization easier, and for making predictions on test set, we will import them also as arrays\n",
    "\n",
    "# We need to reshape images, so that our model will accept it (It expects batch-inputs)\n",
    "new_shape = (1, 250, 250, 3)\n",
    "\n",
    "# Extracting image path using OS\n",
    "bicycle_array = [os.path.join(TEST, 'bicycle', img) for img in os.listdir(os.path.join(TEST, 'bicycle'))]\n",
    "# Reshaping picture so that models will accept them (1,250,250, 3), assigning label and adding PIL.Image render to tuple, so x, y, img = bicycle[i] \n",
    "bicycle = [(np.reshape(cv2.imread(img), new_shape), 0, Image.open(img)) for img in bicycle_array]\n",
    "\n",
    "\n",
    "##Same for the rest...\n",
    "car_array = [os.path.join(TEST, 'car', img) for img in os.listdir(os.path.join(TEST, 'car'))]\n",
    "car = [(np.reshape(cv2.imread(img), new_shape), 1, Image.open(img)) for img in car_array]\n",
    "\n",
    "person_array = [os.path.join(TEST, 'person', img) for img in os.listdir(os.path.join(TEST, 'person'))]\n",
    "person = [(np.reshape(cv2.imread(img), new_shape), 2, Image.open(img)) for img in person_array]\n",
    "\n",
    "# Combining\n",
    "\n",
    "imgs = bicycle_array + car_array + person_array\n",
    "test_set = bicycle + car + person\n",
    "\n",
    "random.shuffle(test_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny VGG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiny VGG Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TinyVGG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(TinyVGG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TinyVGG_results = TinyVGG.evaluate(tensorflow_test)\n",
    "\n",
    "print(f'Sparse Categorical Cross Entropy: {round(TinyVGG_results[0], 2)}\\nPercentage of correct predictions: {TinyVGG_results[1]:0.1%}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1, Precision, Recall, Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting labels and predictions for every image\n",
    "vgg_y_true = []\n",
    "vgg_y_pred = []\n",
    "\n",
    "for img in test_set:\n",
    "    x, y, i = img\n",
    "    \n",
    "    pred = TinyVGG(x)\n",
    "    \n",
    "    vgg_y_true.append(y)\n",
    "    vgg_y_pred.append(np.argmax(pred, axis=1)[0])\n",
    "    \n",
    "# Transforming to arrays to pass through sklearn.metrics\n",
    "vgg_y_true = np.array(vgg_y_true)\n",
    "vgg_y_pred = np.array(vgg_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "vgg_prf = precision_recall_fscore_support(vgg_y_true, vgg_y_pred)\n",
    "\n",
    "# Transform into table\n",
    "table =  [['precision'] + list(vgg_prf[0]),\n",
    "['recall'] + list(vgg_prf[1]),\n",
    "['fscore'] + list(vgg_prf[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print in to tabulate form\n",
    "print(tabulate(table, headers=[\n",
    "      'Metric', class_index[0], class_index[1], class_index[2]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "vgg_cm = confusion_matrix(vgg_y_true, vgg_y_pred, normalize='pred')\n",
    "\n",
    "sns.heatmap(vgg_cm, cmap='Blues', ax=ax, annot=True)\n",
    "\n",
    "# Set the tick labels for x-axis\n",
    "x_ticks = ax.get_xticks().tolist()\n",
    "\n",
    "ax.set_xticklabels([class_index[int(x)] if int(x) in class_index else x for x in x_ticks])\n",
    "\n",
    "# Set the tick labels for y-axis\n",
    "y_ticks = ax.get_yticks().tolist()\n",
    "ax.set_yticklabels([class_index[int(y)] if int(y) in class_index else y for y in y_ticks])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Predictions Across Images\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15, 15))\n",
    "\n",
    "# Looping through ax's\n",
    "for ax in axs.flatten():\n",
    "\n",
    "    # Get random image position\n",
    "    index = random.randint(1, len(test_set)-1)\n",
    "\n",
    "    # Extract images and labels from test set\n",
    "    x, y_true, i = test_set[index]\n",
    "\n",
    "    # Generate Prediction\n",
    "    y_pred = TinyVGG(x)\n",
    "\n",
    "    # Get class with highest probability\n",
    "    y_pred_arg = np.argmax(y_pred, axis=1)[0]\n",
    "\n",
    "    y_pred_prob = np.array(y_pred)[0][y_pred_arg]\n",
    "\n",
    "    y_pred_prob = round(float(y_pred_prob), 2)\n",
    "\n",
    "    ax.imshow(i)\n",
    "    ax.set_title(\n",
    "        f'Predicted label: {class_index[y_pred_arg]} ({y_pred_prob}) True label: {class_index[y_true]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(Xception)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception_results = Xception.evaluate(tensorflow_test)\n",
    "\n",
    "print(\n",
    "    f'Sparse Categorical Cross Entropy Loss: {Xception_results[0]:0.2}\\nPercentage of correct predictions: {Xception_results[1]:0.1%}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1, Precision, Recall, Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting labels and predictions for every image\n",
    "xc_y_true = []\n",
    "xc_y_pred = []\n",
    "\n",
    "for img in test_set:\n",
    "    x, y, i = img\n",
    "    \n",
    "    pred = Xception(x)\n",
    "    \n",
    "    xc_y_true.append(y)\n",
    "    xc_y_pred.append(np.argmax(pred, axis=1)[0])\n",
    "    \n",
    "# Transforming to arrays to pass through sklearn.metrics\n",
    "xc_y_true = np.array(xc_y_true)\n",
    "xc_y_pred = np.array(xc_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception_prf = precision_recall_fscore_support(xc_y_true, xc_y_pred)\n",
    "\n",
    "table =  [['precision'] + list(Xception_prf[0]),\n",
    "['recall'] + list(Xception_prf[1]),\n",
    "['fscore'] + list(Xception_prf[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(table, headers=['Metric', class_index[0], class_index[1], class_index[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "cm = confusion_matrix(xc_y_true, xc_y_pred, normalize='pred')\n",
    "\n",
    "sns.heatmap(cm, cmap='Blues', ax=ax, annot=True)\n",
    "\n",
    "# Set the tick labels for x-axis\n",
    "x_ticks = ax.get_xticks().tolist()\n",
    "\n",
    "ax.set_xticklabels([class_index[int(x)] if int(x) in class_index else x for x in x_ticks])\n",
    "\n",
    "# Set the tick labels for y-axis\n",
    "y_ticks = ax.get_yticks().tolist()\n",
    "ax.set_yticklabels([class_index[int(y)] if int(y) in class_index else y for y in y_ticks])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Predictions Across Images\n",
    "fig, axs = plt.subplots(3,2, figsize=(15,15))\n",
    "\n",
    "# Looping through ax's\n",
    "for ax in axs.flatten():\n",
    "    \n",
    "    # Get random image position\n",
    "    index = random.randint(1, len(test_set)-1)\n",
    "    \n",
    "    # Extract images and labels from test set\n",
    "    x, y_true, i = test_set[index]\n",
    "    \n",
    "    # Generate Prediction\n",
    "    y_pred = Xception(x)\n",
    "    \n",
    "    # Get class with highest probability\n",
    "    y_pred_arg = np.argmax(y_pred, axis=1)[0]\n",
    "    \n",
    "    y_pred_prob = np.array(y_pred)[0][y_pred_arg]\n",
    "    \n",
    "    y_pred_prob = round(float(y_pred_prob), 2)\n",
    "    \n",
    "    ax.imshow(i)\n",
    "    ax.set_title(f'Predicted label: {class_index[y_pred_arg]} ({y_pred_prob}) True label: {class_index[y_true]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
